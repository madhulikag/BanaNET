{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhulikag/BanaNET/blob/main/Bananutrient_multi_class_EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kteItEPHEwwZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Large\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Conv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IaSqrb3Hkjwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849fa7b5-8223-43eb-b112-2ff24d864f08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image directory, change to yours as needed\n",
        "data_dir = '/content/drive/MyDrive/Banana_leaf'\n",
        "\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "-jqM9Rcel_-v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing for unorganized directory\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "CJyzTQ0gmA_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12729ad3-5ad4-41c6-a7cb-85a77737a875"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2657 images belonging to 4 classes.\n",
            "Found 664 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing for organized directory\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Banana_leaf_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Banana_leaf_split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "xu9BpdJ-2rr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b00705-9e92-49a8-838c-a1dcf2f00070"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2657 images belonging to 4 classes.\n",
            "Found 664 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input shape: image size and RGB\n",
        "base_model = MobileNetV3Large(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze base model weights for now\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = base_model(inputs, training=False)  # pass inputs through base model\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "gmCTIv_Myc3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31939971-f3f8-468e-d8ba-d55523619bbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m12683000/12683000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,        # Reduce LR by 50%\n",
        "    patience=2,        # Wait 2 epochs before reducing\n",
        "    min_lr=1e-6,       # Don't go below this LR\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "LUDY6v3n7srN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=30,\n",
        "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h1iMZa1zgCt",
        "outputId": "da6102f1-a82d-472e-d515-dbce44a7731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m43/84\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4:31\u001b[0m 7s/step - accuracy: 0.2467 - loss: 1.8713"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6rMfgtKUPV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(val_generator)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# True labels from the generator\n",
        "y_true = val_generator.classes"
      ],
      "metadata": {
        "id": "0EflNI86UeT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Generate classification report with class names\n",
        "class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))"
      ],
      "metadata": {
        "id": "KxYu_vBdUhyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Generate Confusion matrix with class names\n",
        "class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels,\n",
        "            yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JG0Hk62eU09i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab the MobileNetV3 submodel (by name)\n",
        "base_model = model.get_layer(\"MobileNetV3Large\")\n",
        "\n",
        "# Find its last convolutional layer\n",
        "for layer in reversed(base_model.layers):\n",
        "    if isinstance(layer, (Conv2D, DepthwiseConv2D)):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "print(\"Using conv layer:\", last_conv_layer_name)"
      ],
      "metadata": {
        "id": "-vjEPFde42E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick an example image from your validation set\n",
        "#    (or load one from disk)\n",
        "img_path = val_generator.filepaths[0]      # first val image\n",
        "orig = cv2.imread(img_path)\n",
        "orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
        "resized = cv2.resize(orig, image_size)\n",
        "\n",
        "# Preprocess & batch it\n",
        "x = preprocess_input(resized.astype(np.float32))\n",
        "x = np.expand_dims(x, axis=0)  # shape = (1,224,224,3)"
      ],
      "metadata": {
        "id": "nm3RVi8I69Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Grad-CAM\n",
        "heatmap = make_gradcam_heatmap(x, model, last_conv_layer_name, base_model)\n",
        "\n",
        "# Overlay the heatmap on the original image\n",
        "heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "overlay = cv2.addWeighted(orig, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "# Show results\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(orig); plt.axis(\"off\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"Heatmap\")\n",
        "plt.imshow(heatmap); plt.axis(\"off\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Overlay\")\n",
        "plt.imshow(overlay); plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rXPwfAUN7Dn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOitFg3SVybq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Xg8l6vpTV4vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = model.layers[0]\n",
        "for layer in base_model.layers[::-1]:  # reverse order\n",
        "    if 'conv' in layer.name:\n",
        "        print(layer.name)\n",
        "        break  # first one found in reverse is the last conv layer"
      ],
      "metadata": {
        "id": "cmEEy4XMWO0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_name = \"top_conv\""
      ],
      "metadata": {
        "id": "SfiIvsG9WOJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "# Path to the test image (adjust as needed)\n",
        "img_path = '/content/drive/MyDrive/Banana_leaf/potassium/k3.jpg'\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, axis=0)\n",
        "img_array = tf.keras.applications.mobilenet_v3.preprocess_input(img_array)"
      ],
      "metadata": {
        "id": "kUs3P8fjnG8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_name, base_model)"
      ],
      "metadata": {
        "id": "BTiBCMydWS3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aClb4RWaghF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Banana_leaf'\n",
        "\n",
        "\n",
        "image_size = (300, 300)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "FR8XKIgI9K_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing for unorganized directory\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "gT-0c5pAgkvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(300, 300, 3)  # EfficientNetB3 expects 300x300\n",
        ")\n",
        "base_model.trainable = False  # Freeze initially"
      ],
      "metadata": {
        "id": "0VrxVUvEgtbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,        # Reduce LR by 50%\n",
        "    patience=2,        # Wait 2 epochs before reducing\n",
        "    min_lr=1e-6,       # Don't go below this LR\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "EgxCB93h8vrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(300, 300, 3)),\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(4, activation='softmax')  # change to match your number of classes\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "L3zpnm9Og1yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=30,\n",
        "    callbacks=[reduce_lr, early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "hrTvBEL6g8Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pmen2aRhhKTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(val_generator)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# True labels from the generator\n",
        "y_true = val_generator.classes"
      ],
      "metadata": {
        "id": "OHqUy6X-hO5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report with class names\n",
        "class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))"
      ],
      "metadata": {
        "id": "P0uUlZPxhSNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Generate Confusion matrix with class names\n",
        "class_labels = list(val_generator.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels,\n",
        "            yticklabels=class_labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_TB0u39bhVAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}